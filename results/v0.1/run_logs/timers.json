{
    "name": "root",
    "gauges": {
        "ParkingCarBehavior.Policy.Entropy.mean": {
            "value": 1.1199089288711548,
            "min": 1.1199089288711548,
            "max": 2.0839555263519287,
            "count": 46
        },
        "ParkingCarBehavior.Policy.Entropy.sum": {
            "value": 56012.24609375,
            "min": 56012.24609375,
            "max": 104199.859375,
            "count": 46
        },
        "ParkingCarBehavior.Step.mean": {
            "value": 2299974.0,
            "min": 49961.0,
            "max": 2299974.0,
            "count": 46
        },
        "ParkingCarBehavior.Step.sum": {
            "value": 2299974.0,
            "min": 49961.0,
            "max": 2299974.0,
            "count": 46
        },
        "ParkingCarBehavior.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.029452111572027206,
            "min": -0.18957410752773285,
            "max": 0.03222888335585594,
            "count": 46
        },
        "ParkingCarBehavior.Policy.ExtrinsicValueEstimate.sum": {
            "value": 43.176795959472656,
            "min": -265.21417236328125,
            "max": 45.90826416015625,
            "count": 46
        },
        "ParkingCarBehavior.Environment.EpisodeLength.mean": {
            "value": 55.133557800224466,
            "min": 30.968670076726344,
            "max": 60.65351418002466,
            "count": 46
        },
        "ParkingCarBehavior.Environment.EpisodeLength.sum": {
            "value": 49124.0,
            "min": 48395.0,
            "max": 49223.0,
            "count": 46
        },
        "ParkingCarBehavior.Environment.CumulativeReward.mean": {
            "value": 0.05978227112004293,
            "min": 0.009088889434991152,
            "max": 0.06449773648353568,
            "count": 46
        },
        "ParkingCarBehavior.Environment.CumulativeReward.sum": {
            "value": 53.26600356795825,
            "min": 7.362000442342833,
            "max": 56.88700357847847,
            "count": 46
        },
        "ParkingCarBehavior.Policy.ExtrinsicReward.mean": {
            "value": 0.05978227112004293,
            "min": 0.009088889434991152,
            "max": 0.06449773648353568,
            "count": 46
        },
        "ParkingCarBehavior.Policy.ExtrinsicReward.sum": {
            "value": 53.26600356795825,
            "min": 7.362000442342833,
            "max": 56.88700357847847,
            "count": 46
        },
        "ParkingCarBehavior.Losses.PolicyLoss.mean": {
            "value": 0.023268530533425293,
            "min": 0.021589326323912243,
            "max": 0.0277925506251413,
            "count": 46
        },
        "ParkingCarBehavior.Losses.PolicyLoss.sum": {
            "value": 0.11634265266712647,
            "min": 0.08910998608713272,
            "max": 0.1389627531257065,
            "count": 46
        },
        "ParkingCarBehavior.Losses.ValueLoss.mean": {
            "value": 0.00129423033335479,
            "min": 0.00011873582983389498,
            "max": 0.02316597263619769,
            "count": 46
        },
        "ParkingCarBehavior.Losses.ValueLoss.sum": {
            "value": 0.006471151666773949,
            "min": 0.0005250206179334782,
            "max": 0.09266389054479077,
            "count": 46
        },
        "ParkingCarBehavior.Policy.LearningRate.mean": {
            "value": 0.000231630886789712,
            "min": 0.000231630886789712,
            "max": 0.0002992290977569675,
            "count": 46
        },
        "ParkingCarBehavior.Policy.LearningRate.sum": {
            "value": 0.00115815443394856,
            "min": 0.0009690408769864,
            "max": 0.0014892170135943298,
            "count": 46
        },
        "ParkingCarBehavior.Policy.Epsilon.mean": {
            "value": 0.177210288,
            "min": 0.177210288,
            "max": 0.1997430325,
            "count": 46
        },
        "ParkingCarBehavior.Policy.Epsilon.sum": {
            "value": 0.88605144,
            "min": 0.7230135999999999,
            "max": 0.99640567,
            "count": 46
        },
        "ParkingCarBehavior.Policy.Beta.mean": {
            "value": 0.0038627933712,
            "min": 0.0038627933712,
            "max": 0.00498717732175,
            "count": 46
        },
        "ParkingCarBehavior.Policy.Beta.sum": {
            "value": 0.019313966856000002,
            "min": 0.01615837864,
            "max": 0.024820642933,
            "count": 46
        },
        "ParkingCarBehavior.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 46
        },
        "ParkingCarBehavior.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 46
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1672794276",
        "python_version": "3.10.8 (main, Nov 24 2022, 08:08:27) [Clang 14.0.6 ]",
        "command_line_arguments": "/Users/khalil/miniconda3/envs/env/bin/mlagents-learn /Users/khalil/Documents/GitHub/PraRLParking/configuration.yaml --run-id v0.1",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.11.0",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1672821133"
    },
    "total": 26857.516416999977,
    "count": 1,
    "self": 0.0029470009030774236,
    "children": {
        "run_training.setup": {
            "total": 0.02263970801141113,
            "count": 1,
            "self": 0.02263970801141113
        },
        "TrainerController.start_learning": {
            "total": 26857.490830291063,
            "count": 1,
            "self": 24.315105111338198,
            "children": {
                "TrainerController._reset_env": {
                    "total": 12.753142166999169,
                    "count": 1,
                    "self": 12.753142166999169
                },
                "TrainerController.advance": {
                    "total": 26820.376153553603,
                    "count": 2349502,
                    "self": 20.65271580137778,
                    "children": {
                        "env_step": {
                            "total": 26236.95559399191,
                            "count": 2349502,
                            "self": 24949.051437492133,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 1269.9483935084427,
                                    "count": 2349502,
                                    "self": 45.21910433995072,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 1224.729289168492,
                                            "count": 2302433,
                                            "self": 1224.729289168492
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 17.95576299133245,
                                    "count": 2349501,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 26807.86348622793,
                                            "count": 2349501,
                                            "is_parallel": true,
                                            "self": 3007.725766658783,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0006592090940102935,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.0003233762690797448,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00033583282493054867,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.00033583282493054867
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 23800.13706036005,
                                                    "count": 2349501,
                                                    "is_parallel": true,
                                                    "self": 76.31586046679877,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 165.8997184134787,
                                                            "count": 2349501,
                                                            "is_parallel": true,
                                                            "self": 165.8997184134787
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 23203.903864191496,
                                                            "count": 2349501,
                                                            "is_parallel": true,
                                                            "self": 23203.903864191496
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 354.0176172882784,
                                                            "count": 2349501,
                                                            "is_parallel": true,
                                                            "self": 175.04892012814526,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 178.96869716013316,
                                                                    "count": 4699002,
                                                                    "is_parallel": true,
                                                                    "self": 178.96869716013316
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 562.7678437603172,
                            "count": 2349501,
                            "self": 28.80971221078653,
                            "children": {
                                "process_trajectory": {
                                    "total": 97.78586568322498,
                                    "count": 2349501,
                                    "self": 97.58719455800019,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.19867112522479147,
                                            "count": 4,
                                            "self": 0.19867112522479147
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 436.1722658663057,
                                    "count": 224,
                                    "self": 253.3770730390679,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 182.79519282723777,
                                            "count": 11200,
                                            "self": 182.79519282723777
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 4.5902561396360397e-07,
                    "count": 1,
                    "self": 4.5902561396360397e-07
                },
                "TrainerController._save_models": {
                    "total": 0.04642900009639561,
                    "count": 1,
                    "self": 0.0009172090794891119,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.0455117910169065,
                            "count": 1,
                            "self": 0.0455117910169065
                        }
                    }
                }
            }
        }
    }
}